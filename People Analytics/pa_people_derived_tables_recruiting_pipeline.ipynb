{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvaJRqDZxFUn"
      },
      "outputs": [],
      "source": [
        "## Load Packages\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from geopy.geocoders import GoogleV3\n",
        "from geopy.extra.rate_limiter import RateLimiter\n",
        "from google.cloud import bigquery\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RmAFcQpxFUp",
        "outputId": "54dc3de8-02ff-4a02-c7df-163a132b60f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "409 POST https://bigquery.googleapis.com/bigquery/v2/projects/ppl-stage-bigquery/datasets?prettyPrint=false: Already Exists: Dataset ppl-stage-bigquery:pa_people_derived_tables\n"
          ]
        }
      ],
      "source": [
        "#Setup BigQuery Credentials\n",
        "gbq_credentials = ''\n",
        "\n",
        "#Apply credentials to BigQuery Client\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = gbq_credentials\n",
        "client = bigquery.Client()\n",
        "dataset_id = \"ppl-stage-bigquery.pa_people_derived_tables\"\n",
        "dataset = bigquery.Dataset(dataset_id)\n",
        "dataset.location = \"europe-west2\"\n",
        "try:\n",
        "    dataset = client.create_dataset(dataset)  # API request\n",
        "    print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xoAGXhIxFUq"
      },
      "outputs": [],
      "source": [
        "#SQL Query and project\n",
        "bigquery_project = 'ppl-stage-bigquery'\n",
        "query = \"\"\"WITH offer_fields AS\n",
        "  (\n",
        "    SELECT\n",
        "       lof.offer_id                                                                                             AS offer_id\n",
        "      ,MAX(CASE WHEN lof.text = \"Job Hopper\" THEN lof.value END)                                                AS job_hopper\n",
        "      ,MAX(CASE WHEN lof.text = 'Blockchain Experience at Hire' THEN lof.value END)                             AS blockchain_experience\n",
        "    FROM lever.offer_field lof\n",
        "    GROUP BY offer_id\n",
        "  )\n",
        "SELECT\n",
        "  la.id                                                                                                         AS application_id\n",
        ", la.opportunity_id                                                                                             AS opportunity_id\n",
        ", lo.contact                                                                                                    AS contact_id\n",
        ", lo.name                                                                                                       AS candidate\n",
        ", lo.origin                                                                                                     AS source\n",
        ", lar.text                                                                                                      AS archive_reason\n",
        ", CASE\n",
        "   WHEN lo.archived_at IS NULL THEN 'Active'\n",
        "   WHEN lar.text = 'Hired' THEN 'Hired'\n",
        "   WHEN lar.text IS NOT NULL AND lar.text != 'Hired' THEN 'Rejected'\n",
        "   END                                                                                                          AS application_status\n",
        ", lo.location                                                                                                   AS candidate_location\n",
        ", CAST(lo.archived_at AS DATE)                                                                                  AS archived_at\n",
        ", CAST(lo.last_advanced_at AS DATE)                                                                             AS last_advanced_at\n",
        ", CAST(lo.last_interaction_at AS DATE)                                                                          AS last_interaction_at\n",
        ", CAST(hist.updated_at AS DATE)                                                                                 AS stage_moved_at_date\n",
        ", CASE\n",
        "  WHEN CAST(lo.archived_at AS DATE) IS NOT NULL AND RANK() OVER (PARTITION BY la.id ORDER BY hist.updated_at DESC) = 1\n",
        "  THEN CAST(lo.archived_at AS DATE)\n",
        "  WHEN CAST(lo.archived_at AS DATE) IS NULL AND RANK() OVER (PARTITION BY la.id ORDER BY hist.updated_at DESC) = 1\n",
        "  THEN CAST(hist.updated_at AS DATE)\n",
        "  WHEN RANK() OVER (PARTITION BY la.id ORDER BY hist.updated_at DESC) != 1\n",
        "  THEN CAST(hist.updated_at AS DATE)\n",
        "  END                                                                                                           AS functional_stage_date\n",
        ", DATE_TRUNC\n",
        "    ((CASE\n",
        "  WHEN CAST(lo.archived_at AS DATE) IS NOT NULL AND RANK() OVER (PARTITION BY la.id ORDER BY hist.updated_at DESC) = 1\n",
        "  THEN CAST(lo.archived_at AS DATE)\n",
        "  WHEN CAST(lo.archived_at AS DATE) IS NULL AND RANK() OVER (PARTITION BY la.id ORDER BY hist.updated_at DESC) = 1\n",
        "  THEN CAST(hist.updated_at AS DATE)\n",
        "  WHEN RANK() OVER (PARTITION BY la.id ORDER BY hist.updated_at DESC) != 1\n",
        "  THEN CAST(hist.updated_at AS DATE)\n",
        "  END\n",
        "    )\n",
        "  , WEEK)                                                                                                       AS functional_stage_week\n",
        ", lst.text                                                                                                      AS stage_name\n",
        ", CASE\n",
        "    WHEN lst.text IN ('Offer Extended', 'Offer Approval & Reference Check', 'Verbal Offer & Background Check') THEN 'Offer'\n",
        "    WHEN lst.text = 'Exec/ Advisor/ Enhanced Interview' THEN 'Exec/ Advisor/ Enhanced Interview'\n",
        "    WHEN lst.text = 'Project' THEN 'Project'\n",
        "    WHEN lst.text = 'Team Interview' THEN 'Team Interview'\n",
        "    WHEN lst.text = 'HM Screen' THEN 'HM Screen'\n",
        "    WHEN lst.text = 'Recruiter Screen' THEN 'Recruiter Screen'\n",
        "    WHEN lst.text IN ('Applied', 'Application Review') THEN 'Application Review'\n",
        "    WHEN lst.text = 'Responded' THEN 'Responded'\n",
        "    WHEN lst.text IN ('Email reachout', 'Inmail') THEN 'Reached Out'\n",
        "    WHEN lst.text = 'New lead' THEN 'New Lead'\n",
        "    ELSE ''\n",
        "    END                                                                                                         AS stage_group\n",
        " ,CASE\n",
        "    WHEN RANK() OVER (PARTITION BY la.id ORDER BY hist.updated_at DESC) != 1\n",
        "    THEN DATE_DIFF(CAST(LAG(hist.updated_at) OVER (PARTITION BY la.id ORDER BY CAST(hist.updated_at AS DATE) DESC) AS DATE), CAST(hist.updated_at AS DATE), DAY)\n",
        "    WHEN RANK() OVER (PARTITION BY la.id ORDER BY hist.updated_at DESC) = 1 AND CAST(lo.archived_at AS DATE) IS NOT NULL\n",
        "    THEN DATE_DIFF(CAST(lo.archived_at AS DATE), CAST(hist.updated_at AS DATE), DAY)\n",
        "    WHEN RANK() OVER (PARTITION BY la.id ORDER BY hist.updated_at DESC) = 1 AND CAST(lo.archived_at AS DATE) IS NULL\n",
        "    THEN DATE_DIFF(CURRENT_DATE(), CAST(hist.updated_at AS DATE), DAY)\n",
        "    END                                                                                                         AS days_in_stage\n",
        "  ,RANK() OVER (PARTITION BY la.id ORDER BY hist.updated_at DESC)                                               AS stage_rank\n",
        ",CASE\n",
        "    WHEN RANK() OVER (PARTITION BY la.id ORDER BY hist.updated_at DESC) > 1 THEN 'Completed'\n",
        "    WHEN RANK() OVER (PARTITION BY la.id ORDER BY hist.updated_at DESC) = 1 AND lo.archived_at IS NOT NULL THEN 'Completed'\n",
        "    WHEN RANK() OVER (PARTITION BY la.id ORDER BY hist.updated_at DESC) = 1 AND lo.archived_at IS NULL THEN 'Active'\n",
        "    WHEN RANK() OVER (PARTITION BY la.id ORDER BY hist.updated_at DESC) IS NULL AND lo.archived_at IS NULL THEN 'Active'\n",
        "    END                                                                                                         AS stage_status\n",
        "  ,lu.name                                                                                                      AS recruiting_poc\n",
        "  ,CASE\n",
        "    WHEN lu.deactivated_at IS NOT NULL THEN \"not active\"\n",
        "    WHEN lu.deactivated_at IS NULL THEN \"active\"\n",
        "  END                                                                                                           AS recruiter_status\n",
        "  ,lr.custom_field_dept                                                                                         AS department_at_offer\n",
        "  ,lr.custom_field_subdept                                                                                      AS subteam_at_offer\n",
        "  ,lr.custom_field_level                                                                                        AS level_at_offer\n",
        "  ,lr.employment_status                                                                                         AS employment_status\n",
        "  ,off.blockchain_experience                                                                                    AS blockchain_experience\n",
        "  ,off.job_hopper                                                                                               AS job_hopper\n",
        "FROM lever.opportunity lo\n",
        "    LEFT JOIN\n",
        "      lever.application la\n",
        "      ON lo.id = la.opportunity_id\n",
        "    LEFT JOIN\n",
        "      lever.archive_reason lar\n",
        "      ON lo.archived_reason_id = lar.id\n",
        "    LEFT JOIN\n",
        "      lever.opportunity_stage_history hist\n",
        "      ON lo.id = hist.opportunity_id\n",
        "    LEFT JOIN\n",
        "      lever.stage lst\n",
        "      ON hist.stage_id = lst.id\n",
        "    LEFT JOIN\n",
        "      lever.user lu\n",
        "      ON lo.owner_id = lu.id\n",
        "    LEFT JOIN\n",
        "      lever.requisition lr\n",
        "      ON la.requisition_for_hire_id = lr.id\n",
        "    LEFT JOIN\n",
        "      lever.offer offer\n",
        "      ON lo.id = offer.opportunity_id\n",
        "    LEFT JOIN\n",
        "      offer_fields off\n",
        "      ON offer.id = off.offer_id\n",
        "ORDER BY opportunity_id DESC, stage_rank ASC\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GW2B5NPuxFUs"
      },
      "outputs": [],
      "source": [
        "#specify the project and result\n",
        "query_job = client.query(query, project=bigquery_project)\n",
        "results = query_job.result()\n",
        "\n",
        "#print results back to GBQ\n",
        "df = (\n",
        "    results.to_dataframe()\n",
        "    .result()\n",
        "    .to_dataframe()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZI2CvffxFUt",
        "outputId": "ce9fc050-998a-44c1-97b8-8c2171988271"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LoadJob<project=ppl-stage-bigquery, location=europe-west2, id=c95add7c-2c90-4c99-85df-a1137bf26819>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define the new schema\n",
        "new_schema = [\n",
        "    bigquery.SchemaField(\"application_id\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"opportunity_id\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"contact_id\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"candidate\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"source\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"archive_reason\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"application_status\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"candidate_location\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"archived_at\", \"DATE\"),\n",
        "    bigquery.SchemaField(\"last_advanced_at\", \"DATE\"),\n",
        "    bigquery.SchemaField(\"last_interaction_at\", \"DATE\"),\n",
        "    bigquery.SchemaField(\"stage_moved_at_date\", \"DATE\"),\n",
        "    bigquery.SchemaField(\"functional_stage_date\", \"DATE\"),\n",
        "    bigquery.SchemaField(\"functional_stage_week\", \"DATE\"),\n",
        "    bigquery.SchemaField(\"stage_name\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"stage_group\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"days_in_stage\", \"INTEGER\"),\n",
        "    bigquery.SchemaField(\"stage_rank\", \"INTEGER\"),\n",
        "    bigquery.SchemaField(\"stage_status\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"recruiting_poc\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"recruiter_status\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"department_at_offer\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"subteam_at_offer\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"level_at_offer\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"employment_status\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"blockchain_experience\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"job_hopper\", \"STRING\")\n",
        "\n",
        "\n",
        "    # Add or modify fields as necessary\n",
        "]\n",
        "\n",
        "#create a derived destination table\n",
        "destination_table = f\"{client.project}.{dataset_id}.pa_people_derived_tables\"\n",
        "\n",
        "# Set up the job configuration with the new schema\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    schema=new_schema,\n",
        "    schema_update_options=[\n",
        "        bigquery.SchemaUpdateOption.ALLOW_FIELD_ADDITION\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Load the DataFrame into BigQuery using the defined schema\n",
        "client.delete_table(destination_table, not_found_ok=True)  # for debugging only - remove in production\n",
        "job = client.load_table_from_dataframe(df, destination_table, job_config=job_config)\n",
        "job.result()  # Wait for the job to complete"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/josephd100/people_analytics.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMqv_ZpOxwb1",
        "outputId": "84262693-d0d1-4027-ac3f-182ad1accca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'people_analytics' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "id": "c_m_HGIzyBN7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}